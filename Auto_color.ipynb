{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OB0VGvf_zUwg"
   },
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import tensorflow as tf #open source library for machine learning and it is end to end\n",
    "from tensorflow.keras.utils import img_to_array,array_to_img,load_img #Public Keras utilities\n",
    "from skimage.io import imsave #Skimage reads the image, converts it from JPEG into a NumPy array, and returns the array\n",
    "import numpy as np #for working with arrays\n",
    "from skimage import color\n",
    "import os #for opening files etc\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcngzGPVZPXG"
   },
   "outputs": [],
   "source": [
    "#Getting Images\n",
    "\n",
    "X = []\n",
    "for imagename in os.listdir('Dataset/Train/'):#takes the filename of all images\n",
    "    X.append(img_to_array(load_img('Dataset/Train/'+imagename)))#takes every image in directory and loads it and then convert to array and add it into the list\n",
    "X = np.array(X, dtype=float) #converts X which is a list to array and changes datatype to float\n",
    "\n",
    "\n",
    "# Set up train and test data\n",
    "\n",
    "split = int(0.95*len(X)) #splitting the data \n",
    "Xtrain = X[:split] \n",
    "Xtrain = 1.0/255*Xtrain #normalization of training data to standardize data and it improves the accuracy and integrity of your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQluK8okZdS-"
   },
   "outputs": [],
   "source": [
    "#CNN model\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, InputLayer\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential() #Sequential is the easiest way to build a model in Keras. It allows you to build a model layer by layer.one input one output\n",
    "\n",
    "#Input Layer\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(256, 256, 1), activation='relu', padding='same'))#input shape 3 tuples so 3 dimensions 256,256 is the pixels\n",
    "\n",
    "\n",
    "#Hidden Layers\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))#rectified linear is the most used activation function for all CNN models.we use relu because it helps prevent expotential growth in computation.\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))#Conv2D is convolution layer this layer creates a convolution kernel\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))# the number of pixels shifts over the input matrix. When the stride is 1 then we move the filters to 1 pixel at a time.\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))#padding can be either valid or same. same means padding with zeros evenly\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))#512 is the numbers of filters that convolutional layers will learn from.(3,3) is the kernel size the number must be odd\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))#a simple scaling up of the image by using nearest neighbour or bilinear upsampling, so nothing smart. Advantage is it's cheap.(2,2) is the size indicating no. of columns and rows.\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(2, (3, 3), activation='softmax', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "#Compiling the CNN\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics = ['accuracy'])#RMSProp uses the second moment by with a decay rate to speed up from AdaGrad. Adam uses both first and second moments of the gradient, and is generally the best choice\n",
    "#we tried adam and rmsprop and sgd adam is better than sgd for cnn as its more efficent\n",
    "#loss is measured with mean squared error\n",
    "#metrics used to judge performance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17535
    },
    "colab_type": "code",
    "id": "eUkYfqqUuWrd",
    "outputId": "3d80459c-1bd1-4c2f-d2b8-5d191dc6bf13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "30/30 [==============================] - 55s 2s/step - loss: 0.2349 - accuracy: 0.5540\n",
      "Epoch 2/500\n",
      "30/30 [==============================] - 54s 2s/step - loss: 0.2224 - accuracy: 0.5596\n",
      "Epoch 3/500\n",
      " 6/30 [=====>........................] - ETA: 48s - loss: 0.2208 - accuracy: 0.5550"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Image transformer\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True)#image data generation takes the original data and transforms based on parameters passed and adds this data to the original data and runs this.This is called data augmention.\n",
    "\n",
    "# Generate training data\n",
    "batch_size = 10\n",
    "def image_a_b_gen(batch_size):\n",
    "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
    "        lab_batch = color.rgb2lab(batch)\n",
    "        X_batch = lab_batch[:,:,:,0]\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)\n",
    "\n",
    "# Train model      \n",
    "tensorboard = TensorBoard(log_dir=\"/output/beta_run\")\n",
    "trainedmodel = model.fit(image_a_b_gen(batch_size), callbacks=[tensorboard],epochs=500, steps_per_epoch=30)\n",
    "\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(trainedmodel.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(trainedmodel.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2VD886hawiN"
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G7R1KkZm1RPs"
   },
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "\n",
    "from keras.models import model_from_json\n",
    "json_file = open('trainedmodel.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"trainedmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "B7-LmhPPbaTM",
    "outputId": "7c847cbf-c88d-43b0-a678-a857cda2e58f"
   },
   "outputs": [],
   "source": [
    "# Manual Testing of Images\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(23, 2, figsize=(16,100))\n",
    "row = 0\n",
    "colorize = []\n",
    "print('Output of the Model')\n",
    "for filename in os.listdir('Dataset/Test/'):\n",
    "\timage = Image.open('Dataset/Test/'+filename)\n",
    "\tnew_image = image.resize((256, 256))\n",
    "\tnew_image.save('Dataset/Test/'+filename)\n",
    "\tcolorize.append(img_to_array(load_img('Dataset/Test/'+filename)))\n",
    "\tax[row,0].imshow(load_img('Dataset/Test/'+filename), interpolation='nearest')\n",
    "\trow +=1\n",
    "\n",
    "colorize = np.array(colorize, dtype=float)\n",
    "colorize = color.rgb2lab(1.0/255*colorize)[:,:,:,0]\n",
    "colorize = colorize.reshape(colorize.shape+(1,))\n",
    "\n",
    "\n",
    "# Test model\n",
    "output = loaded_model.predict(colorize)\n",
    "output = output * 128\n",
    "\n",
    "row = 0\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "\tcur = np.zeros((256, 256, 3))\n",
    "\tcur[:,:,0] = colorize[i][:,:,0]\n",
    "\tcur[:,:,1:] = output[i]\n",
    "\tresImage = color.lab2rgb(cur)\n",
    "\tax[row,1].imshow(resImage, interpolation='nearest')\n",
    "\trow += 1\n",
    "    \n",
    "\n",
    "# \timsave(\"result/img_\"+str(i)+\".png\", resImage)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Auto color.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "df95319d8ce4e1d89f5365ae10992bc1f65da593082b1d264e8f529830ec2f02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
