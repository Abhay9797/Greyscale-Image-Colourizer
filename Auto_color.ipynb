{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OB0VGvf_zUwg"
   },
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import tensorflow as tf #open source library for machine learning and it is end to end\n",
    "from tensorflow.keras.utils import img_to_array,array_to_img,load_img #Public Keras utilities\n",
    "from skimage.io import imsave #Skimage reads the image, converts it from JPEG into a NumPy array, and returns the array\n",
    "import numpy as np #for working with arrays\n",
    "from skimage import color\n",
    "import os #for opening files etc\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcngzGPVZPXG"
   },
   "outputs": [],
   "source": [
    "#Getting Images\n",
    "\n",
    "X = []\n",
    "for imagename in os.listdir('Dataset/Train/'):#takes the filename of all images\n",
    "    X.append(img_to_array(load_img('Dataset/Train/'+imagename)))#takes every image in directory and loads it and then convert to array and add it into the list\n",
    "X = np.array(X, dtype=float) #converts X which is a list to array and changes datatype to float\n",
    "\n",
    "\n",
    "# Set up train and test data\n",
    "\n",
    "split = int(0.95*len(X)) #splitting the data \n",
    "Xtrain = X[:split] \n",
    "Xtrain = 1.0/255*Xtrain #normalization of training data to standardize data and it improves the accuracy and integrity of your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQluK8okZdS-"
   },
   "outputs": [],
   "source": [
    "#CNN model\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, InputLayer\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential() #Sequential is the easiest way to build a model in Keras. It allows you to build a model layer by layer.one input one output\n",
    "\n",
    "#Input Layer\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(256, 256, 1), activation='relu', padding='same'))#input shape 3 tuples so 3 dimensions 256,256 is the pixels\n",
    "\n",
    "\n",
    "#Hidden Layers\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))#rectified linear is the most used activation function for all CNN models.we use relu because it helps prevent expotential growth in computation.\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))#Conv2D is convolution layer this layer creates a convolution kernel\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))# the number of pixels shifts over the input matrix. When the stride is 1 then we move the filters to 1 pixel at a time.\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))#padding can be either valid or same. same means padding with zeros evenly\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))#512 is the numbers of filters that convolutional layers will learn from.(3,3) is the kernel size the number must be odd\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))#a simple scaling up of the image by using nearest neighbour or bilinear upsampling, so nothing smart. Advantage is it's cheap.(2,2) is the size indicating no. of columns and rows.\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(2, (3, 3), activation='softmax', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "#Compiling the CNN\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics = ['accuracy'])#RMSProp uses the second moment by with a decay rate to speed up from AdaGrad. Adam uses both first and second moments of the gradient, and is generally the best choice\n",
    "#we tried adam and rmsprop and sgd adam is better than sgd for cnn as its more efficent\n",
    "#loss is measured with mean squared error\n",
    "#metrics used to judge performance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17535
    },
    "colab_type": "code",
    "id": "eUkYfqqUuWrd",
    "outputId": "3d80459c-1bd1-4c2f-d2b8-5d191dc6bf13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "30/30 [==============================] - 55s 2s/step - loss: 0.2349 - accuracy: 0.5540\n",
      "Epoch 2/500\n",
      "30/30 [==============================] - 54s 2s/step - loss: 0.2224 - accuracy: 0.5596\n",
      "Epoch 3/500\n",
      " 6/30 [=====>........................] - ETA: 48s - loss: 0.2208 - accuracy: 0.5550"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Image augmentation helps in improving size of training set without getting new images and help improve prediction\n",
    "# Image transformer\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True)#image data generation takes the original data and transforms based on parameters passed and adds this data to the original data and runs this.This is called data augmention.\n",
    "\n",
    "# Generate training data\n",
    "batch_size = 10\n",
    "def image_a_b_gen(batch_size):\n",
    "    for batch in datagen.flow(Xtrain, batch_size=batch_size):  #datagen.flow generates batches of tensor images with real-time data augmentation(artificially increasing amount of data)\n",
    "        lab_batch = color.rgb2lab(batch) #converts training piture from rbg to lab colorspace. it needs a 3d array as input [[[0.1,0.2,0.3]]]\n",
    "        X_batch = lab_batch[:,:,:,0] #L channel\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128 #ab channel, the two batches are the splitting of lab colors for prevention of overfitting\n",
    "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch) #The reason for reshaping is to ensure that the input data to the model is in the correct shape\n",
    "\n",
    "# Train model      \n",
    "tensorboard = TensorBoard(log_dir=\"/output/beta_run\")\n",
    "trainedmodel = model.fit(image_a_b_gen(batch_size), callbacks=[tensorboard],epochs=500, steps_per_epoch=30)\n",
    "\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(trainedmodel.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(trainedmodel.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2VD886hawiN"
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G7R1KkZm1RPs"
   },
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "\n",
    "from keras.models import model_from_json\n",
    "json_file = open('trainedmodel.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"trainedmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "B7-LmhPPbaTM",
    "outputId": "7c847cbf-c88d-43b0-a678-a857cda2e58f"
   },
   "outputs": [],
   "source": [
    "# Manual Testing of Images\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "%matplotlib inline #sets the backend of matplotlib to inline (shows the plots in the jupyter notebook)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(23, 2, figsize=(16,100)) #returns a tuple containing fig and axes objects, 23,2 = rows,columns.. if 3,2.. then axes will be like [[ax1,ax2],[ax3,ax4],[ax5,ax6]]\n",
    "row = 0\n",
    "colorize = []\n",
    "print('Output of the Model')\n",
    "for filename in os.listdir('Dataset/Test/'): #gets all the files in the entered directory\n",
    "\timage = Image.open('Dataset/Test/'+filename) #reads the image\n",
    "\tnew_image = image.resize((256, 256)) #resizes the image to 256x256\n",
    "\tnew_image.save('Dataset/Test/'+filename)\n",
    "\tcolorize.append(img_to_array(load_img('Dataset/Test/'+filename))) #load_img reads the image from the file and then it is converted into a numpy array \n",
    "\tax[row,0].imshow(load_img('Dataset/Test/'+filename), interpolation='nearest') #imshow is openCV func to display img in window\n",
    "\trow +=1 #interpolate is when we try to estimate unknown data points b/w two data points, interpolation = nearest displays the img without trying to interpolate b/w pixels\n",
    "\n",
    "colorize = np.array(colorize, dtype=float) #converts the image array to float values\n",
    "colorize = color.rgb2lab(1.0/255*colorize)[:,:,:,0] #L space of the Lab colorspace\n",
    "colorize = colorize.reshape(colorize.shape+(1,)) #.shape() gives the shape of the numpy array, (no. of arrays, no. of values in each array)\n",
    "#reshapes colorize to include one more array \n",
    "\n",
    "# Test model\n",
    "output = loaded_model.predict(colorize) #predicts the labels of the data values based on the trained model\n",
    "output = output * 128 #to get the true color value in Lab colorspace(ranges between -128 to 128)\n",
    "row = 0\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "\tcur = np.zeros((256, 256, 3)) #creates a black background\n",
    "\tcur[:,:,0] = colorize[i][:,:,0] #copy grayscale layer from test image\n",
    "\tcur[:,:,1:] = output[i] #add other two color layers\n",
    "\tresImage = color.lab2rgb(cur) \n",
    "\tax[row,1].imshow(resImage, interpolation='nearest') #display the image on the notebook\n",
    "\trow += 1\n",
    "    \n",
    "\n",
    "# \timsave(\"result/img_\"+str(i)+\".png\", resImage)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Auto color.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "eae1e3a4314c157d4988bb3a6bad3d3a31838ca3e30d3370421c51e16fc5956d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
